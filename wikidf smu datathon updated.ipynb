{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54d12f30-5970-4a21-9966-51f8b51db18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mani7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mani7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mani7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\mani7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string as st\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sent = SentimentIntensityAnalyzer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5311f2f4-472a-4549-aa13-a3a519a262cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidf = pd.read_excel('C:/Users/mani7/Desktop/smu datathon/wikileaks_parsed.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c4f3797-7ad1-4a62-90e9-de8842608f42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF Path</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.pdf</td>\n",
       "      <td>Pristina Airport – Possible administrative irr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.pdf</td>\n",
       "      <td>Investigative details\\n\\nIn his/her interviews...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"An interoffice memorandum providing an “outst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"Allegation 2 &amp; 3:\\n\\n(Specifically, three of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"When asked about this in interview, the Divis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"INVESTIGATION DETAILS\\n\\nThis part of the inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"At paragraph 4 of the Cargo Apron Extension e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"Until the end of June 2002, responsibility fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"METHODOLOGY\\n\\nThis investigation was conduct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"Allegation 4:\\n\\n(Specifically, that the Vend...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PDF Path                                               Text\n",
       "0    1.pdf  Pristina Airport – Possible administrative irr...\n",
       "1    1.pdf  Investigative details\\n\\nIn his/her interviews...\n",
       "2   10.pdf  \"An interoffice memorandum providing an “outst...\n",
       "3   10.pdf  \"Allegation 2 & 3:\\n\\n(Specifically, three of ...\n",
       "4   10.pdf  \"When asked about this in interview, the Divis...\n",
       "5   10.pdf  \"INVESTIGATION DETAILS\\n\\nThis part of the inv...\n",
       "6   10.pdf  \"At paragraph 4 of the Cargo Apron Extension e...\n",
       "7   10.pdf  \"Until the end of June 2002, responsibility fo...\n",
       "8   10.pdf  \"METHODOLOGY\\n\\nThis investigation was conduct...\n",
       "9   10.pdf  \"Allegation 4:\\n\\n(Specifically, that the Vend..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e95a1a7-992f-450f-a0b8-28240288ab58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wikidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f40a65d-7e5b-421c-8709-3415a4a97521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Path    False\n",
      "Text        False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "empty_columnss = wikidf.isnull().all(axis=0)\n",
    "print(empty_columnss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66aa2e63-f5da-4d82-aa90-ab057d486c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text (Text) for the first row:\n",
      "\n",
      "Pristina Airport – Possible administrative irregularity regarding tender procedures involving Vendor 1 and Vendor 2\n",
      "\n",
      "Allegation\n",
      "\n",
      "Two companies with the same owner took part at least three times in the same Airport tenders.\n",
      "\n",
      "Background Information\n",
      "\n",
      "The Kosovo citizen, Vendor 1 and Vendor 2 Representative, is the owner and Director of the Pristina-based Vendor 1 and also a 51% shareholder of the Pristina-Ljubljana-based company Vendor 2. Both companies have their residences at the same address in Pristina.\n",
      "\n",
      "Both Vendor 1 and Vendor 2 submitted three times in 2003 for the same tenders:\n",
      "\n",
      "Supply and Mounting of Sonic System in the Fire Station Building. Winner was Vendor 2 with €1,530 followed by Vendor 1 with €1,620. The third company, Vendor 3, did not provide a price offer.\n",
      "\n",
      "Cabling of Flat Display Information System (FIDS). Winner was Vendor 1 with €15,919 followed by Vendor 2 with €19,248.70. The other two competitors, Vendor 3 and Vendor 4, offered prices of Euro 19,702 and Euro 21,045.\n",
      "\n",
      "Purchase and fixing of Cramer Antenna. Winner was again Vendor 1 with €3,627.99 followed by Vendor 2 with €3,921. The other two competitors, Vendor 3 and Vendor 4, offered prices of €4,278 and €4,670.\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text (Text) for the first row:\")\n",
    "print(\"\")\n",
    "print(wikidf['Text'].iloc[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45408914-bc97-41ce-9bd1-0076627bae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove punctuation except for spaces\n",
    "    text = \"\".join([ch for ch in text if ch not in st.punctuation])\n",
    "    \n",
    "    # Tokenize and convert to lowercase\n",
    "    tokens = re.split(r'\\s+', text.lower())\n",
    "    \n",
    "    # Keep \"number + unit\" patterns together\n",
    "    combined_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Check for \"number or currency + unit\"\n",
    "        if i + 1 < len(tokens) and re.match(r'^(€|\\$|£)?\\d+(\\.\\d+)?$', tokens[i]) and tokens[i + 1] in {\"million\", \"billion\", \"thousand\"}:\n",
    "            combined_tokens.append(f\"{tokens[i]} {tokens[i + 1]}\")\n",
    "            i += 2  # Skip the next token as it is already combined\n",
    "        else:\n",
    "            combined_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    custom_stopwords = set(stopwords.words('english')).union({'said', 'also', 'one', 'mr', 'per', 'u', '–', 'm'})\n",
    "    filtered_tokens = [word for word in combined_tokens if word not in custom_stopwords]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    \n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef1ba6ac-5ff8-4f63-b27f-ac0af79e3a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF Path</th>\n",
       "      <th>Text</th>\n",
       "      <th>cleaned text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.pdf</td>\n",
       "      <td>Pristina Airport – Possible administrative irr...</td>\n",
       "      <td>[pristina, airport, possible, administrative, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.pdf</td>\n",
       "      <td>Investigative details\\n\\nIn his/her interviews...</td>\n",
       "      <td>[investigative, detail, hisher, interview, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"An interoffice memorandum providing an “outst...</td>\n",
       "      <td>[interoffice, memorandum, providing, “outstand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"Allegation 2 &amp; 3:\\n\\n(Specifically, three of ...</td>\n",
       "      <td>[allegation, 2, 3, specifically, three, person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"When asked about this in interview, the Divis...</td>\n",
       "      <td>[asked, interview, divisional, manager, stated...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PDF Path                                               Text  \\\n",
       "0    1.pdf  Pristina Airport – Possible administrative irr...   \n",
       "1    1.pdf  Investigative details\\n\\nIn his/her interviews...   \n",
       "2   10.pdf  \"An interoffice memorandum providing an “outst...   \n",
       "3   10.pdf  \"Allegation 2 & 3:\\n\\n(Specifically, three of ...   \n",
       "4   10.pdf  \"When asked about this in interview, the Divis...   \n",
       "\n",
       "                                        cleaned text  \n",
       "0  [pristina, airport, possible, administrative, ...  \n",
       "1  [investigative, detail, hisher, interview, con...  \n",
       "2  [interoffice, memorandum, providing, “outstand...  \n",
       "3  [allegation, 2, 3, specifically, three, person...  \n",
       "4  [asked, interview, divisional, manager, stated...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidf['cleaned text'] = wikidf['Text'].apply(lambda x: preprocess_text(x))\n",
    "wikidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c76fb7e-d6fa-47ed-8ba9-c03d6020a0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text after cleaning for the first row:\n",
      "\n",
      "['investigation', 'detail', 'part', 'investigation', 'relates', 'tender', 'contract', 'extension', 'cargo', 'terminal', 'apron', 'pristina', 'airport', 'value', 'contract', '€77431863', 'allegation', '1', 'specifically', 'tender', 'document', 'cargo', 'apron', 'comply', 'requirement', 'article', '234', 'unmik', 'finance', 'administrative', 'instruction', '19992', 'public', 'procurement', 'using', 'kosovo', 'consolidated', 'budget', 'fund', 'based', 'summary', 'document', 'include', 'clear', 'instruction', 'drawing', 'plan', 'note', 'project', 'engineer', 'evaluation', 'company', 'peap', 'official', 'dated', '31', 'january', '2001', 'indicates', 'evaluation', 'company', 'commissioned', 'produce', 'preliminary', 'design', 'cargo', 'terminal', 'pristina', 'airport', 'design', 'provided', 'construction', 'cargo', 'apron', 'extension']\n"
     ]
    }
   ],
   "source": [
    "print(\"Text after cleaning for the first row:\")\n",
    "print(\"\")\n",
    "print(wikidf['cleaned text'].iloc[5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08c21cd3-92ed-4083-8717-c6ff5369c3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Unigrams:\n",
      "official: 255\n",
      "airport: 242\n",
      "1: 227\n",
      "staff: 150\n",
      "pristina: 134\n",
      "2: 132\n",
      "vendor: 129\n",
      "member: 126\n",
      "officer: 117\n",
      "procurement: 111\n",
      "\n",
      "Top 10 Bigrams:\n",
      "staff member: 92\n",
      "pristina airport: 82\n",
      "official 1: 60\n",
      "vendor 1: 46\n",
      "doti official: 46\n",
      "atcs official: 39\n",
      "officer 1: 38\n",
      "official 2: 37\n",
      "finance officer: 37\n",
      "vendor 2: 35\n",
      "\n",
      "Top 10 Trigrams:\n",
      "doti official 1: 27\n",
      "pristina international airport: 27\n",
      "non staff member: 24\n",
      "staff member 1: 23\n",
      "procurement officer 1: 21\n",
      "doti official 2: 18\n",
      "end june 2002: 16\n",
      "2002 responsibility administration: 15\n",
      "dra logistics officer: 13\n",
      "unep staff member: 13\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "# Combine all preprocessed tokens into a single list\n",
    "all_tokens = list(chain.from_iterable(wikidf['cleaned text']))\n",
    "\n",
    "# Extract bigrams\n",
    "bigrams = list(ngrams(all_tokens, 2))\n",
    "bigram_counts = Counter(bigrams)\n",
    "\n",
    "# Extract trigrams\n",
    "trigrams = list(ngrams(all_tokens, 3))\n",
    "trigram_counts = Counter(trigrams)\n",
    "\n",
    "# Extract 4 word phrases\n",
    "fourgrams = list(ngrams(all_tokens, 4))\n",
    "fourgram_counts = Counter(fourgrams)\n",
    "\n",
    "# Display top 10 bigrams and trigrams\n",
    "\n",
    "print(\"\\nTop 10 Bigrams:\")\n",
    "for bigram, count in bigram_counts.most_common(10):\n",
    "    print(f\"{' '.join(bigram)}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 Trigrams:\")\n",
    "for trigram, count in trigram_counts.most_common(10):\n",
    "    print(f\"{' '.join(trigram)}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 Four word phrases:\")\n",
    "for trigram, count in fourgram_counts.most_common(10):\n",
    "    print(f\"{' '.join(trigram)}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1345099-b7a7-4ac7-8b5b-0bf75fdb22ba",
   "metadata": {},
   "source": [
    "# sentimental analysis using vader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ecb86-6a36-441c-80d3-eacf819246a0",
   "metadata": {},
   "source": [
    "### identifying link domains  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf42e798-df00-4731-bdca-40784ceddd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PDF Path\n",
       "2.pdf      17\n",
       "10.pdf     10\n",
       "82.pdf     10\n",
       "47.pdf      9\n",
       "16.pdf      8\n",
       "4.pdf       8\n",
       "69.pdf      7\n",
       "49.pdf      6\n",
       "24.pdf      5\n",
       "27.pdf      4\n",
       "13.pdf      4\n",
       "38.pdf      4\n",
       "51.pdf      3\n",
       "44.pdf      3\n",
       "52.pdf      3\n",
       "89.pdf      3\n",
       "9.pdf       3\n",
       "73.pdf      2\n",
       "1.pdf       2\n",
       "35.pdf      2\n",
       "26.pdf      2\n",
       "105.pdf     2\n",
       "15.pdf      2\n",
       "14.pdf      2\n",
       "108.pdf     2\n",
       "11.pdf      2\n",
       "111.pdf     1\n",
       "106.pdf     1\n",
       "107.pdf     1\n",
       "8.pdf       1\n",
       "63.pdf      1\n",
       "60.pdf      1\n",
       "110.pdf     1\n",
       "5.pdf       1\n",
       "31.pdf      1\n",
       "112.pdf     1\n",
       "113.pdf     1\n",
       "45.pdf      1\n",
       "114.pdf     1\n",
       "43.pdf      1\n",
       "39.pdf      1\n",
       "36.pdf      1\n",
       "21.pdf      1\n",
       "91.pdf      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidf[\"PDF Path\"]. value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d931d42d-0c8c-48a8-8de1-71ce78ff49aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mani7\\AppData\\Local\\Temp\\ipykernel_27332\\3208561539.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  wikidf.iloc[0][1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Pristina Airport – Possible administrative irregularity regarding tender procedures involving Vendor 1 and Vendor 2\\n\\nAllegation\\n\\nTwo companies with the same owner took part at least three times in the same Airport tenders.\\n\\nBackground Information\\n\\nThe Kosovo citizen, Vendor 1 and Vendor 2 Representative, is the owner and Director of the Pristina-based Vendor 1 and also a 51% shareholder of the Pristina-Ljubljana-based company Vendor 2. Both companies have their residences at the same address in Pristina.\\n\\nBoth Vendor 1 and Vendor 2 submitted three times in 2003 for the same tenders:\\n\\nSupply and Mounting of Sonic System in the Fire Station Building. Winner was Vendor 2 with €1,530 followed by Vendor 1 with €1,620. The third company, Vendor 3, did not provide a price offer.\\n\\nCabling of Flat Display Information System (FIDS). Winner was Vendor 1 with €15,919 followed by Vendor 2 with €19,248.70. The other two competitors, Vendor 3 and Vendor 4, offered prices of Euro 19,702 and Euro 21,045.\\n\\nPurchase and fixing of Cramer Antenna. Winner was again Vendor 1 with €3,627.99 followed by Vendor 2 with €3,921. The other two competitors, Vendor 3 and Vendor 4, offered prices of €4,278 and €4,670.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidf.iloc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8692a892-8723-429a-979d-814a1386445e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mani7\\AppData\\Local\\Temp\\ipykernel_27332\\3988460483.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  sent.polarity_scores(wikidf.iloc[0][1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.013, 'neu': 0.91, 'pos': 0.078, 'compound': 0.9042}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.polarity_scores(wikidf.iloc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a64b427-da68-434e-955a-c5f2ef37b2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mani7\\AppData\\Local\\Temp\\ipykernel_27332\\2427545874.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  senti_rating = sent.polarity_scores(wikidf.iloc[0][1])\n"
     ]
    }
   ],
   "source": [
    "senti_rating = sent.polarity_scores(wikidf.iloc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "247356f0-0e16-477b-ab9f-23acb0b96a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(senti_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8af1581-1987-468d-8f4d-901261e76e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_rating['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27086bf-f3de-4f01-95a5-5865d3fd4541",
   "metadata": {},
   "source": [
    "### assigning scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a7e12cc-1570-4e29-a4ab-73323be14ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mani7\\AppData\\Local\\Temp\\ipykernel_27332\\1445940691.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  score = sent.polarity_scores(wikidf.iloc[i][1])\n"
     ]
    }
   ],
   "source": [
    "score_com = []\n",
    "score_pos = []\n",
    "score_neg = []\n",
    "for i in range(0, wikidf.shape[0]):\n",
    "    score = sent.polarity_scores(wikidf.iloc[i][1])\n",
    "    score1 = score['compound']\n",
    "    score_com.append(score1)\n",
    "\n",
    "    score2 = score['pos']\n",
    "    score_pos.append(score2)\n",
    "\n",
    "    score3 = score['neg']\n",
    "    score_neg.append(score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d84398a1-7bee-4aca-96e4-1b07f4f776cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidf[\"Pos Score\"] = score_pos\n",
    "wikidf[\"Neg Score\"] = score_neg\n",
    "wikidf[\"Comp Score\"] = score_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b4e061d-8437-4a27-b4aa-d0a635e24e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34277f39-fabb-4a28-a6ed-fc7cfa2306b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF Path</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pos Score</th>\n",
       "      <th>Neg Score</th>\n",
       "      <th>Comp Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.pdf</td>\n",
       "      <td>Pristina Airport – Possible administrative irr...</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.9042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.pdf</td>\n",
       "      <td>Investigative details\\n\\nIn his/her interviews...</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"An interoffice memorandum providing an “outst...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"Allegation 2 &amp; 3:\\n\\n(Specifically, three of ...</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"When asked about this in interview, the Divis...</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.0900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PDF Path                                               Text  Pos Score  \\\n",
       "0    1.pdf  Pristina Airport – Possible administrative irr...      0.078   \n",
       "1    1.pdf  Investigative details\\n\\nIn his/her interviews...      0.092   \n",
       "2   10.pdf  \"An interoffice memorandum providing an “outst...      0.000   \n",
       "3   10.pdf  \"Allegation 2 & 3:\\n\\n(Specifically, three of ...      0.051   \n",
       "4   10.pdf  \"When asked about this in interview, the Divis...      0.056   \n",
       "\n",
       "   Neg Score  Comp Score  \n",
       "0      0.013      0.9042  \n",
       "1      0.092     -0.2500  \n",
       "2      0.000      0.0000  \n",
       "3      0.014      0.6249  \n",
       "4      0.053      0.0900  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6ff5fa9-1702-4cf6-9fda-7f18f8465f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27020139860139863"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidf[\"Comp Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b86b79a-d429-4574-abc3-c491e10e9a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF Path</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pos Score</th>\n",
       "      <th>Neg Score</th>\n",
       "      <th>Comp Score</th>\n",
       "      <th>Overall Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.pdf</td>\n",
       "      <td>Pristina Airport – Possible administrative irr...</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.pdf</td>\n",
       "      <td>Investigative details\\n\\nIn his/her interviews...</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"An interoffice memorandum providing an “outst...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"Allegation 2 &amp; 3:\\n\\n(Specifically, three of ...</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"When asked about this in interview, the Divis...</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"INVESTIGATION DETAILS\\n\\nThis part of the inv...</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"At paragraph 4 of the Cargo Apron Extension e...</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.4559</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"Until the end of June 2002, responsibility fo...</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"METHODOLOGY\\n\\nThis investigation was conduct...</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.pdf</td>\n",
       "      <td>\"Allegation 4:\\n\\n(Specifically, that the Vend...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PDF Path                                               Text  Pos Score  \\\n",
       "0    1.pdf  Pristina Airport – Possible administrative irr...      0.078   \n",
       "1    1.pdf  Investigative details\\n\\nIn his/her interviews...      0.092   \n",
       "2   10.pdf  \"An interoffice memorandum providing an “outst...      0.000   \n",
       "3   10.pdf  \"Allegation 2 & 3:\\n\\n(Specifically, three of ...      0.051   \n",
       "4   10.pdf  \"When asked about this in interview, the Divis...      0.056   \n",
       "5   10.pdf  \"INVESTIGATION DETAILS\\n\\nThis part of the inv...      0.019   \n",
       "6   10.pdf  \"At paragraph 4 of the Cargo Apron Extension e...      0.012   \n",
       "7   10.pdf  \"Until the end of June 2002, responsibility fo...      0.035   \n",
       "8   10.pdf  \"METHODOLOGY\\n\\nThis investigation was conduct...      0.067   \n",
       "9   10.pdf  \"Allegation 4:\\n\\n(Specifically, that the Vend...      0.020   \n",
       "\n",
       "   Neg Score  Comp Score Overall Rating  \n",
       "0      0.013      0.9042       Positive  \n",
       "1      0.092     -0.2500       Negative  \n",
       "2      0.000      0.0000       Negative  \n",
       "3      0.014      0.6249       Positive  \n",
       "4      0.053      0.0900       Negative  \n",
       "5      0.017      0.0557       Negative  \n",
       "6      0.033     -0.4559       Negative  \n",
       "7      0.000      0.7845       Positive  \n",
       "8      0.025      0.7506       Positive  \n",
       "9      0.009      0.2263       Negative  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidf['Overall Rating'] = wikidf['Comp Score'].apply(lambda x: 'Positive' if x > 0.5 else 'Negative')\n",
    "\n",
    "wikidf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b9bb207-f38a-492d-ac9b-35506b8d1749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Overall Rating\n",
       "Negative    79\n",
       "Positive    64\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidf['Overall Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b006d02-637a-4240-93b2-56114b5ec5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
